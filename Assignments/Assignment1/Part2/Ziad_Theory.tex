\documentclass{article}
\usepackage[utf8]{inputenc}
\usepackage[margin = 1.1in, headheight = 0.9in, footskip = 0.75 in]{geometry}
\usepackage{fancyhdr}
\usepackage{lastpage}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{xparse}
\usepackage{graphicx}
\usepackage{enumerate}
\usepackage{mathtools}
\usepackage{amsthm}
\usepackage{tikz-cd}
\usepackage{tikz}
\usepackage{pgfplots}
\usepackage[shortlabels]{enumitem}
\newcommand{\RNum}[1]{\uppercase\expandafter{\romannumeral #1\relax}}
\newcommand\ddfrac[2]{\frac{\displaystyle #1}{\displaystyle #2}}
\usepackage{xpatch}
\setlength{\parindent}{3em}
\setlength{\parskip}{0.5em}
%===================================================================================================
\pagestyle{fancyplain}
\renewcommand{\headrulewidth}{0pt}
\renewcommand{\footrulewidth}{0pt}
\fancyhf{}\par 
\lhead{\hspace{0cm}\\\hspace{0cm}\\Zmh6339\\AI \& Machine Learning, CS-UH 3260\\Professor Keith Ross}
\rhead{Ziad Hassan\\January 31, 2024}
\cfoot{\thepage/\pageref{LastPage}}
%===================================================================================================
\title{Assignment 1}
\date{}
\author{}
%===================================================================================================
\begin{document}
\maketitle
%==================================================================================================
\section*{Part 1: Continuous Bandit Algorithm}
%==================================================================================================
\section*{Part 2: Theory}
\begin{enumerate}[a)]
    \item \begin{proof}
        \renewcommand{\qedsymbol}{$\blacksquare$}
        \hfill\\\\
        \begin{equation*}
            \begin{aligned}
                P(\text{greedy action}) &= 1 - P(\text{not greedy action})\\
                &= 1 - P(\text{not greedy selection \textit{AND} not greedy action})\\
                &= 1 - P(\text{not greedy selection}) \cdot P(\text{not greedy action $|$ not greedy selection})\\
                &= 1 - \epsilon \cdot \left(\ddfrac{k-1}{k}\right) \textit{\hspace{1cm}$^{*}$ Since there is only \textbf{one} greedy action}\\
                &= 1 - \epsilon \cdot \left(1-\ddfrac{1}{k}\right)\\
                &= 1 - \epsilon + \ddfrac{\epsilon}{k}\\
            \end{aligned}
        \end{equation*}
    \end{proof}
    %==============================================
    \item  
    \begin{enumerate}[i)]
        \item \begin{proof}
            \renewcommand{\qedsymbol}{$\blacksquare$}
            \hfill\\\\
            To determine the probability that the greedy action was chosen for the first time at time $T$, we need to consider that it was not chosen at any time before $T$, and that it was chosen at time $T$.\\
            Thus, the following equation should be quantified:
            \begin{equation*}
                P(\text{greedy at } T) = P(\text{not greedy before } T) \cdot P(\text{greedy at } T)
            \end{equation*}
            Therefore, the probability that the greedy action was chosen for the first time at time $T$ is:
            \begin{equation*}
                \begin{aligned}
                    P(\text{greedy at } T) &= P(\text{not greedy before } T) \cdot P(\text{greedy at } T)\\
                    &= \left(1 - 1 + \epsilon - \frac{\epsilon}{k}\right)^{T - 1} \cdot \left(1 - \epsilon + \frac{\epsilon}{k}\right)\\
                    &= \left(\epsilon - \frac{\epsilon}{k}\right)^{T - 1} \cdot \left(1 - \epsilon + \frac{\epsilon}{k}\right)\\
                \end{aligned}
            \end{equation*}\par
        \end{proof}

    \item \begin{proof}
        \renewcommand{\qedsymbol}{$\blacksquare$}
        \hfill\\\\
        To get the expected number of steps, $\mathbb{E}[T]$, until the the greedy action is chosen for the first time is a sum over all possible time steps, each weighted by its probability of being the first time the greedy action is chosen.\\
        Thus, the following equation should be quantified:
        \begin{equation*}
            \mathbb{E}[T] = \sum_{t = 1}^{\infty} t \cdot P(\text{greedy at } t)
        \end{equation*}
        Following, the equation is 
        \begin{equation*}
            \begin{aligned}
                \mathbb{E}[T] &= \sum_{t = 1}^{\infty} t \cdot P(\text{greedy at } t)\\
                &= \sum_{t = 1}^{\infty} t \cdot \left(\epsilon - \frac{\epsilon}{k}\right)^{t - 1} \cdot \left(1 - \epsilon + \frac{\epsilon}{k}\right)\\
            \end{aligned}
        \end{equation*}
        It can be observed that the above equation is a geometric series, which can be simplified to the following:
        \begin{equation*}
            \begin{aligned}
                \mathbb{E}[T] &= \sum_{t = 1}^{\infty} t \cdot \left(\epsilon - \frac{\epsilon}{k}\right)^{t - 1} \cdot \left(1 - \epsilon + \frac{\epsilon}{k}\right)\\
                &= \ddfrac{1}{\left(\epsilon - \frac{\epsilon}{k}\right)^{t - 1} \cdot \left(1 - \epsilon + \frac{\epsilon}{k}\right)}
            \end{aligned}
        \end{equation*}\par
        The above simplifciation is valid due to the definiton of the expected value of a geometric series.\par 
    \end{proof}
    \end{enumerate}
    %==============================================
    \item 
    \begin{enumerate}[i)]
        \item 
        \begin{proof}
            \renewcommand{\qedsymbol}{$\blacksquare$}
            \hfill\\\\
            Firstly, denote $\max(q(1), q(2), \dots, q(10))$ as $q_{*}$.\\
            The algorithm will choose the greedy selection, $q_{*}$ with probability $1 - \epsilon$, and a non-greedy selection with probability $\epsilon$.\\
            Moreover, the expected value of the an action during non-greedy selection is the average of all the action values, which is $\frac{\sum_{i = 1}^{10} q(i)}{10}$.\\
            Therefore, the long-run reward is 
            \begin{equation*}
                R = (1 - \epsilon) \cdot q_{*} + \epsilon \cdot \frac{\sum_{i = 1}^{10} q(i)}{10}
            \end{equation*}\par 
        \end{proof}
        
        \item 
        \begin{proof}
           \renewcommand{\qedsymbol}{$\blacksquare$}
            \hfill\\\\
           Since $q(1), q(2), \dots, q(10)$ are i.i.d. random variables, the expected value of a greedy action becomes $\mathbb{E}[q_{*}] = b$.\\
           Moreover, since $q(a)$ is $\mathcal{N}(0,1)$, the expected average of all the action values becomes $\mathbb{E}\left[\frac{\sum_{i = 1}^{10} q(i)}{10}\right] = 0$.\\
           Therefore, the long-run reward is
           \begin{equation*}
               \begin{aligned}
                   R &= (1 - \epsilon) \cdot \mathbb{E}[q_{*}] + \epsilon \cdot \mathbb{E}\left[\frac{\sum_{i = 1}^{10} q(i)}{10}\right]\\
                   &= (1 - \epsilon) \cdot b + \epsilon \cdot 0\\
                   &= (1 - \epsilon) \cdot b
               \end{aligned}
           \end{equation*}\par 
        \end{proof}
    \end{enumerate}
\end{enumerate}
%==================================================================================================
\end{document}